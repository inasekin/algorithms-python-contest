\documentclass[9pt,landscape,a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[margin=0.4cm]{geometry}
\usepackage{multicol}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}

\setlength{\parindent}{0pt}
\setlength{\parskip}{2pt}
\setlength{\columnsep}{6pt}
\setlist{nolistsep,leftmargin=*,itemsep=1pt}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\rk}{rk}

\begin{document}
\footnotesize
\begin{multicols}{3}

\section*{ОПРЕДЕЛЕНИЯ (ПОЛНЫЕ ФОРМУЛИРОВКИ)}

\subsection*{1. Сложение и вычитание матриц}
Пусть $A=(a_{ij})$ и $B=(b_{ij})$ — матрицы одинакового размера $m\times n$. Тогда их \textbf{сумма} $A+B$ — матрица размера $m\times n$ с элементами $(A+B)_{ij}=a_{ij}+b_{ij}$. \textbf{Разность} определяется аналогично: $(A-B)_{ij}=a_{ij}-b_{ij}$.

\subsection*{2. Произведение матрицы на число}
Пусть $A=(a_{ij})$ — матрица размера $m\times n$, $\alpha\in\R$ (или $\C$). Тогда $\alpha A$ — матрица размера $m\times n$ с элементами $(\alpha A)_{ij}=\alpha\cdot a_{ij}$.

\subsection*{3. Произведение матриц}
Пусть $A=(a_{ij})$ размера $m\times n$ и $B=(b_{jk})$ размера $n\times p$. Тогда их \textbf{произведение} $AB$ — матрица размера $m\times p$ с элементами $(AB)_{ik}=\sum_{j=1}^n a_{ij}b_{jk}$.

\subsection*{4. Нулевая матрица. Единичная матрица}
\textbf{Нулевая матрица} $O$ (или $0$) размера $m\times n$ — матрица, все элементы которой равны нулю.

\textbf{Единичная матрица} $E$ (или $I$) размера $n\times n$ — квадратная матрица с элементами $e_{ij}=\delta_{ij}$ (символ Кронекера: $\delta_{ij}=1$ при $i=j$ и $\delta_{ij}=0$ при $i\ne j$). То есть на главной диагонали стоят единицы, остальные элементы — нули.

\subsection*{5. Главная диагональ квадратной матрицы}
Для квадратной матрицы $A=(a_{ij})$ размера $n\times n$ \textbf{главная диагональ} — это набор элементов $a_{11}, a_{22}, a_{33}, \ldots, a_{nn}$.

\subsection*{6. Транспонирование матрицы}
Пусть $A=(a_{ij})$ — матрица размера $m\times n$. Тогда \textbf{транспонированная матрица} $A^T$ — матрица размера $n\times m$ с элементами $(A^T)_{ij}=a_{ji}$ (строки и столбцы меняются местами).

\subsection*{7. Степень матрицы}
Для квадратной матрицы $A$ размера $n\times n$ и натурального $k$ определяем $A^k=\underbrace{A\cdot A\cdot\ldots\cdot A}_{k\text{ раз}}$. По определению $A^0=E$, $A^1=A$.

\subsection*{8. Многочлен от матрицы}
Пусть $P(x)=c_0+c_1x+c_2x^2+\cdots+c_dx^d$ — многочлен с коэффициентами из $\R$ (или $\C$), $A$ — квадратная матрица. Тогда $P(A)=c_0E+c_1A+c_2A^2+\cdots+c_dA^d$.

\subsection*{9. След матрицы}
Для квадратной матрицы $A=(a_{ij})$ размера $n\times n$ \textbf{след} определяется как $\Tr A=\sum_{i=1}^n a_{ii}$ (сумма элементов главной диагонали).

\subsection*{10. Обратимая матрица. Обратная матрица}
Квадратная матрица $A$ размера $n\times n$ называется \textbf{обратимой} (или невырожденной), если существует матрица $B$ такая, что $AB=BA=E$. Такая матрица $B$ называется \textbf{обратной} к $A$ и обозначается $A^{-1}$.

\subsection*{11. Верхнетреугольная матрица}
Квадратная матрица $A=(a_{ij})$ называется \textbf{верхнетреугольной}, если $a_{ij}=0$ при всех $i>j$ (все элементы ниже главной диагонали равны нулю). Аналогично определяется \textbf{нижнетреугольная} матрица.

\subsection*{12. Матрица коэффициентов и расширенная матрица СЛАУ}
Для системы линейных алгебраических уравнений
\[\begin{cases}
a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=b_1\\
a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2\\
\vdots\\
a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n=b_m
\end{cases}\]
\textbf{матрица коэффициентов} — это $A=(a_{ij})$ размера $m\times n$. \textbf{Расширенная матрица коэффициентов} — это $(A|b)$ размера $m\times(n+1)$, где $b=(b_1,\ldots,b_m)^T$ — столбец свободных членов.

\subsection*{13. Решение системы}
\textbf{Решение} СЛАУ $Ax=b$ — это набор чисел $(x_1,x_2,\ldots,x_n)$ (или вектор-столбец $x$), который при подстановке обращает все уравнения системы в верные равенства.

\subsection*{14. Ступенчатый вид матрицы}
Матрица находится в \textbf{ступенчатом виде}, если:
\begin{itemize}
\item Все нулевые строки (если есть) находятся внизу;
\item Для каждой ненулевой строки лидер (первый ненулевой элемент) находится правее лидера предыдущей строки.
\end{itemize}

\subsection*{15. Улучшенный ступенчатый вид матрицы}
Матрица находится в \textbf{улучшенном ступенчатом виде} (или приведённом ступенчатом виде), если:
\begin{itemize}
\item Она в ступенчатом виде;
\item Каждый лидер равен 1;
\item В каждом столбце, содержащем лидер, все остальные элементы равны нулю.
\end{itemize}

\subsection*{16. Совместная СЛАУ}
СЛАУ называется \textbf{совместной}, если она имеет хотя бы одно решение. В противном случае система называется \textbf{несовместной}.

\subsection*{17. Определённая СЛАУ}
Совместная СЛАУ называется \textbf{определённой}, если она имеет единственное решение. Если решений бесконечно много, система называется \textbf{неопределённой}.

\subsection*{18. Эквивалентные СЛАУ}
Две СЛАУ называются \textbf{эквивалентными}, если они имеют одинаковое множество решений (то есть любое решение первой системы является решением второй, и наоборот).

\subsection*{19. Однородная СЛАУ. Нулевое решение}
СЛАУ называется \textbf{однородной}, если все свободные члены равны нулю: $Ax=0$. \textbf{Нулевое (тривиальное) решение} однородной системы — это $x=0$ (все переменные равны нулю).

\subsection*{20. Элементарное преобразование I типа}
Прибавление к одной строке другой строки, умноженной на число: $s_i\to s_i+\alpha s_j$, где $i\ne j$, $\alpha$ — любое число.

\subsection*{21. Элементарное преобразование II типа}
Перестановка (обмен) двух строк: $s_i\leftrightarrow s_j$.

\subsection*{22. Элементарное преобразование III типа}
Умножение строки на ненулевое число: $s_i\to\alpha s_i$, где $\alpha\ne0$.

\subsection*{23. Экзотическое уравнение}
В процессе решения СЛАУ может возникнуть уравнение вида $0=b$, где $b\ne0$ (все коэффициенты при переменных равны нулю, а свободный член ненулевой). Такое уравнение называется \textbf{экзотическим} и свидетельствует о несовместности системы.

\subsection*{24. Лидер (ведущий элемент) строки}
\textbf{Лидер} строки матрицы — это первый (самый левый) ненулевой элемент этой строки.

\subsection*{25. Главные переменные}
При решении СЛАУ в ступенчатом виде \textbf{главные переменные} — это переменные, соответствующие столбцам, в которых находятся лидеры строк.

\subsection*{26. Свободные переменные}
\textbf{Свободные переменные} — это переменные, которые не являются главными (столбцы без лидеров). Им можно придавать произвольные значения.

\subsection*{27. Подстановка. Двустрочная запись}
\textbf{Подстановка} $\sigma$ из $n$ элементов — это биективное отображение $\{1,2,\ldots,n\}\to\{1,2,\ldots,n\}$.

\textbf{Двустрочная запись:} $\sigma=\begin{pmatrix}1&2&\cdots&n\\\sigma(1)&\sigma(2)&\cdots&\sigma(n)\end{pmatrix}$.

\textbf{Стандартный вид} двустрочной записи — когда в верхней строке элементы идут по порядку $1,2,\ldots,n$.

\subsection*{28. Произведение (композиция) подстановок}
Для подстановок $\sigma$ и $\tau$ их \textbf{композиция} (произведение) $\sigma\tau$ определяется как $(\sigma\tau)(i)=\sigma(\tau(i))$ (сначала применяется $\tau$, потом $\sigma$).

\subsection*{29. Цикл (подстановка). Транспозиция}
\textbf{Цикл} длины $k$ — это подстановка вида $(a_1\,a_2\,\ldots\,a_k)$, которая действует по правилу: $a_1\to a_2\to a_3\to\cdots\to a_k\to a_1$, а остальные элементы оставляет на месте.

\textbf{Транспозиция} — это цикл длины 2: $(a\,b)$ меняет местами $a$ и $b$.

\subsection*{30. Независимые циклы}
Два или более цикла называются \textbf{независимыми}, если они не имеют общих элементов (действуют на разных элементах множества $\{1,2,\ldots,n\}$).

\subsection*{31. Порядок подстановки}
\textbf{Порядок} подстановки $\sigma$ — это наименьшее натуральное число $k$ такое, что $\sigma^k=e$ (тождественная подстановка).

\subsection*{32. Инверсия}
\textbf{Инверсия} в подстановке $\sigma$ — это пара индексов $(i,j)$ такая, что $i<j$, но $\sigma(i)>\sigma(j)$ (больший элемент стоит левее меньшего).

\subsection*{33. Чётность подстановки}
Подстановка называется \textbf{чётной}, если число инверсий в ней чётное, и \textbf{нечётной}, если число инверсий нечётное.

\subsection*{34. Знак подстановки}
\textbf{Знак} подстановки $\sigma$ определяется как $\sgn(\sigma)=(-1)^{\text{число инверсий в }\sigma}$. То есть $\sgn(\sigma)=+1$ для чётных подстановок и $\sgn(\sigma)=-1$ для нечётных.

\subsection*{35. Определитель}
\textbf{Определитель} (детерминант) квадратной матрицы $A=(a_{ij})$ размера $n\times n$ определяется формулой:
\[\det A=\sum_{\sigma\in S_n}\sgn(\sigma)\cdot a_{1,\sigma(1)}\cdot a_{2,\sigma(2)}\cdots a_{n,\sigma(n)},\]
где суммирование ведётся по всем подстановкам $\sigma$ из $n$ элементов.

Обозначения: $\det A$, $|A|$, $\begin{vmatrix}a_{11}&\cdots&a_{1n}\\\vdots&&\vdots\\a_{n1}&\cdots&a_{nn}\end{vmatrix}$.

\subsection*{36. Минор}
\textbf{Минор} $M_{ij}$ матрицы $A$ — это определитель подматрицы, полученной из $A$ вычёркиванием $i$-й строки и $j$-го столбца.

\subsection*{37. Алгебраическое дополнение}
\textbf{Алгебраическое дополнение} элемента $a_{ij}$ определяется как $A_{ij}=(-1)^{i+j}M_{ij}$.

\subsection*{38. Присоединённая (союзная) матрица}
\textbf{Присоединённая} (или \textbf{союзная}) \textbf{матрица} $A^*$ (или $\mathrm{adj}\,A$) — это транспонированная матрица алгебраических дополнений: $A^*=(A_{ji})$, то есть $(A^*)_{ij}=A_{ji}$.

\subsection*{39. Комплексные числа, их сложение и умножение}
\textbf{Комплексное число} — это упорядоченная пара $(a,b)$ действительных чисел $a,b\in\R$.

\textbf{Сложение:} $(a,b)+(c,d)=(a+c,b+d)$.

\textbf{Умножение:} $(a,b)\cdot(c,d)=(ac-bd,ad+bc)$.

Обычно записывают $z=a+bi$, где $i$ — мнимая единица ($i^2=-1$), $a=\mathrm{Re}\,z$ (действительная часть), $b=\mathrm{Im}\,z$ (мнимая часть).

\subsection*{40. Модуль комплексного числа}
\textbf{Модуль} комплексного числа $z=a+bi$ определяется как $|z|=\sqrt{a^2+b^2}$ (расстояние от начала координат до точки $(a,b)$ на комплексной плоскости).

\subsection*{41. Аргумент комплексного числа}
\textbf{Аргумент} комплексного числа $z=a+bi$ (обозначение: $\arg z$) — это угол $\varphi$ такой, что $z=|z|(\cos\varphi+i\sin\varphi)$. Аргумент определён с точностью до $2\pi k$, $k\in\mathbb{Z}$. Главное значение аргумента: $\varphi\in(-\pi,\pi]$ или $\varphi\in[0,2\pi)$.

\subsection*{42. Алгебраическая и тригонометрическая запись}
\textbf{Алгебраическая форма:} $z=a+bi$, где $a,b\in\R$.

\textbf{Тригонометрическая форма:} $z=r(\cos\varphi+i\sin\varphi)$, где $r=|z|$ — модуль, $\varphi=\arg z$ — аргумент.

Связь: $a=r\cos\varphi$, $b=r\sin\varphi$.

\subsection*{43. Комплексное сопряжение}
Для комплексного числа $z=a+bi$ \textbf{комплексно сопряжённое} число определяется как $\bar{z}=a-bi$ (меняется знак мнимой части). Геометрически — отражение относительно действительной оси.

\subsection*{44. Комплексный корень}
\textbf{Корень $n$-й степени} из комплексного числа $z=r(\cos\varphi+i\sin\varphi)$ — это множество из $n$ комплексных чисел:
\[w_k=\sqrt[n]{r}\left(\cos\frac{\varphi+2\pi k}{n}+i\sin\frac{\varphi+2\pi k}{n}\right),\quad k=0,1,2,\ldots,n-1.\]
Обозначение: $\sqrt[n]{z}$ или $z^{1/n}$.

\subsection*{45. Векторное пространство (8 условий)}
\textbf{Векторное пространство} над полем $\mathbb{F}$ (обычно $\R$ или $\C$) — это множество $V$ с операциями сложения $(+): V\times V\to V$ и умножения на скаляр $(\cdot):\mathbb{F}\times V\to V$, удовлетворяющими 8 аксиомам:

1. $(u+v)+w=u+(v+w)$ (ассоциативность сложения);

2. $u+v=v+u$ (коммутативность);

3. $\exists 0\in V: v+0=v$ $\forall v\in V$ (существование нулевого вектора);

4. $\forall v\in V\,\exists(-v)\in V: v+(-v)=0$ (существование противоположного);

5. $(\alpha\beta)v=\alpha(\beta v)$ (ассоциативность умножения на скаляр);

6. $1\cdot v=v$ (нейтральность единицы);

7. $\alpha(u+v)=\alpha u+\alpha v$ (дистрибутивность относительно сложения векторов);

8. $(\alpha+\beta)v=\alpha v+\beta v$ (дистрибутивность относительно сложения скаляров).

\subsection*{46. Векторное подпространство}
\textbf{Подпространство} векторного пространства $V$ — это непустое подмножество $U\subseteq V$, которое само является векторным пространством с теми же операциями (замкнуто относительно сложения и умножения на скаляр).

\subsection*{47. Линейная комбинация. Тривиальная л.к.}
\textbf{Линейная комбинация} векторов $v_1,v_2,\ldots,v_k$ — это вектор вида $\alpha_1v_1+\alpha_2v_2+\cdots+\alpha_kv_k$, где $\alpha_1,\ldots,\alpha_k$ — скаляры.

\textbf{Тривиальная линейная комбинация} — это когда все коэффициенты равны нулю: $\alpha_1=\alpha_2=\cdots=\alpha_k=0$.

\subsection*{48. Линейно зависимая система векторов}
Система векторов $v_1,v_2,\ldots,v_k$ называется \textbf{линейно зависимой}, если существует их нетривиальная линейная комбинация, равная нулевому вектору:
\[\alpha_1v_1+\alpha_2v_2+\cdots+\alpha_kv_k=0,\]
где не все $\alpha_i$ равны нулю.

Система называется \textbf{линейно независимой}, если из $\sum\alpha_iv_i=0$ следует, что все $\alpha_i=0$.

\subsection*{49. Линейная оболочка системы векторов}
\textbf{Линейная оболочка} системы векторов $v_1,\ldots,v_k$ (обозначения: $\langle v_1,\ldots,v_k\rangle$, $\mathrm{span}\{v_1,\ldots,v_k\}$, $\mathrm{Lin}\{v_1,\ldots,v_k\}$) — это множество всех их линейных комбинаций:
\[\langle v_1,\ldots,v_k\rangle=\{\alpha_1v_1+\cdots+\alpha_kv_k\mid\alpha_1,\ldots,\alpha_k\in\mathbb{F}\}.\]
Это наименьшее подпространство, содержащее все векторы $v_1,\ldots,v_k$.

\subsection*{50. Полная подсистема. Полная система}
Подсистема $\{v_{i_1},\ldots,v_{i_m}\}\subseteq\{v_1,\ldots,v_k\}$ называется \textbf{полной} (в системе $\{v_1,\ldots,v_k\}$), если $\langle v_{i_1},\ldots,v_{i_m}\rangle=\langle v_1,\ldots,v_k\rangle$.

Система $\{v_1,\ldots,v_k\}$ называется \textbf{полной} в векторном пространстве $V$, если $\langle v_1,\ldots,v_k\rangle=V$ (любой вектор из $V$ представим как их линейная комбинация).

\subsection*{51. Базис системы векторов}
\textbf{Базис} системы векторов $\{v_1,\ldots,v_k\}$ — это максимальная линейно независимая подсистема. Эквивалентно: минимальная полная подсистема.

\subsection*{52. Координаты вектора относительно базиса}
Если $\{e_1,\ldots,e_n\}$ — базис векторного пространства $V$ и $v\in V$, то существует единственное представление $v=\alpha_1e_1+\cdots+\alpha_ne_n$. Числа $\alpha_1,\ldots,\alpha_n$ называются \textbf{координатами} вектора $v$ в базисе $\{e_1,\ldots,e_n\}$.

\subsection*{53. Ранг системы векторов}
\textbf{Ранг} системы векторов $\{v_1,\ldots,v_k\}$ (обозначение: $\rk\{v_1,\ldots,v_k\}$) — это размер её базиса (число векторов в базисе системы). Равен максимальному числу линейно независимых векторов в системе.

\subsection*{54. Размерность векторного пространства}
\textbf{Размерность} векторного пространства $V$ (обозначение: $\dim V$) — это число векторов в любом его базисе. Все базисы конечномерного векторного пространства имеют одинаковое число элементов.

\end{multicols}

\newpage

\begin{multicols}{3}

\section*{ФОРМУЛИРОВКИ ТЕОРЕМ (БЕЗ ДОКАЗАТЕЛЬСТВ)}

\subsection*{Матрицы и СЛАУ}

\textbf{1. Ассоциативность произведения матриц:} $(AB)C=A(BC)$ (когда размеры согласованы).

\textbf{2. Дистрибутивность:} $(A+B)C=AC+BC$ и $A(B+C)=AB+AC$.

\textbf{3. Свойства обратных матриц:}
\begin{itemize}
\item $E^{-1}=E$;
\item $(A^{-1})^{-1}=A$;
\item $(AB)^{-1}=B^{-1}A^{-1}$ (если $A,B$ обратимы);
\item $(A^T)^{-1}=(A^{-1})^T$.
\end{itemize}

\textbf{4. След произведения:} $\Tr(AB)=\Tr(BA)$ (для квадратных матриц подходящих размеров).

\textbf{5. Единственность обратной:} Если обратная матрица существует, то она единственна.

\textbf{6. Эквивалентность при ЭП I типа:} Если к одной строке системы прибавить другую, умноженную на число, то новая система эквивалентна исходной.

\textbf{7. Теорема о решениях при фиксированном наборе свободных переменных:} При фиксированных значениях свободных переменных однородная система имеет единственное решение, а неоднородная — либо единственное решение, либо несовместна.

\textbf{8. Количество решений СЛАУ:} Любая СЛАУ имеет либо 0 решений (несовместна), либо ровно 1 решение (определена), либо бесконечно много решений (неопределена).

\subsection*{Подстановки}

\textbf{9. Количество подстановок:} Множество всех подстановок из $n$ элементов имеет $n!$ элементов.

\textbf{10. Ассоциативность композиции:} $(\sigma\tau)\rho=\sigma(\tau\rho)$.

\textbf{11. Теорема о разложении в независимые циклы:} Любая подстановка единственным образом (с точностью до порядка сомножителей) представляется в виде произведения независимых циклов.

\textbf{12. Утверждение о возведении цикла в степень:} Цикл длины $k$ при возведении в степень $m$ распадается на $\gcd(k,m)$ независимых циклов длины $k/\gcd(k,m)$.

\textbf{13. Теорема о порядке подстановки в терминах независимых циклов:} Порядок подстановки равен НОК длин циклов в её разложении на независимые циклы.

\textbf{14. Теорема о произведении произвольной подстановки на транспозицию:} $\sigma(i\,j)$ меняет местами значения $\sigma(i)$ и $\sigma(j)$, остальные элементы оставляет без изменений.

\textbf{15. Лемма о чётности произведения подстановки на транспозицию:} $\sgn(\sigma(i\,j))=-\sgn(\sigma)$ (знак меняется на противоположный).

\textbf{16. Лемма о разложении подстановки на транспозиции:} Любая подстановка представима в виде произведения транспозиций.

\textbf{17. Теорема о чётности подстановки в терминах транспозиций:} Чётность подстановки не зависит от способа её разложения на транспозиции (если в одном разложении чётное число транспозиций, то и в любом другом — чётное).

\textbf{18. Теорема о знаке композиции подстановок:} $\sgn(\sigma\tau)=\sgn(\sigma)\cdot\sgn(\tau)$.

\textit{Следствие о знаке обратной:} $\sgn(\sigma^{-1})=\sgn(\sigma)$.

\subsection*{Определители}

\textbf{19. Определитель транспонированной матрицы:} $\det(A^T)=\det A$.

\textbf{20. Теорема о полилинейности определителя:} Определитель — полилинейная функция от строк (столбцов), то есть линеен по каждой строке при фиксированных остальных.

\textbf{21. Свойство кососимметричности определителя:} При перестановке двух строк (столбцов) определитель меняет знак.

\textit{Следствие:} Если две строки (столбца) равны, то определитель равен нулю.

\textbf{22. Определитель треугольной матрицы:} Определитель верхне- или нижнетреугольной матрицы равен произведению элементов на главной диагонали.

\textbf{23. Изменение определителя при элементарных операциях:}
\begin{itemize}
\item ЭП I типа ($s_i\to s_i+\alpha s_j$): определитель не меняется;
\item ЭП II типа ($s_i\leftrightarrow s_j$): определитель меняет знак;
\item ЭП III типа ($s_i\to\alpha s_i$): определитель умножается на $\alpha$.
\end{itemize}

\textbf{24. Теорема об определителе с углом нулей:}
\[\det\begin{pmatrix}A&B\\0&C\end{pmatrix}=\det A\cdot\det C,\]
где $A$ и $C$ — квадратные матрицы.

\textbf{25. Теорема об определителе произведения:} $\det(AB)=\det A\cdot\det B$.

\textbf{26. Теорема о разложении определителя по строке (или столбцу):}
\[\det A=\sum_{j=1}^n a_{ij}A_{ij}=\sum_{i=1}^n a_{ij}A_{ij},\]
где $A_{ij}$ — алгебраические дополнения.

\textbf{27. Теорема о фальшивом разложении:}
\[\sum_{j=1}^n a_{ij}A_{kj}=0\quad\text{при }i\ne k\]
(разложение элементов одной строки по алгебраическим дополнениям другой даёт ноль).

\textbf{28. Теорема о присоединённой (союзной) матрице:} $AA^*=A^*A=(\det A)\cdot E$.

\textit{Явная формула для обратной:} Если $\det A\ne0$, то $A^{-1}=\frac{1}{\det A}A^*$.

\textbf{29. Теорема Крамера:} Если $\det A\ne0$, то система $Ax=b$ имеет единственное решение:
\[x_i=\frac{\det A_i}{\det A},\]
где $A_i$ — матрица, полученная из $A$ заменой $i$-го столбца на столбец $b$.

\textbf{30. Определитель Вандермонда:}
\[\det\begin{pmatrix}
1&1&\cdots&1\\
x_1&x_2&\cdots&x_n\\
x_1^2&x_2^2&\cdots&x_n^2\\
\vdots&\vdots&&\vdots\\
x_1^{n-1}&x_2^{n-1}&\cdots&x_n^{n-1}
\end{pmatrix}=\prod_{1\le i<j\le n}(x_j-x_i).\]

\subsection*{Многочлены и комплексные числа}

\textbf{31. Теорема об интерполяционном многочлене Лагранжа:} Для любых попарно различных точек $x_1,\ldots,x_n$ и любых значений $y_1,\ldots,y_n$ существует единственный многочлен $P(x)$ степени не выше $n-1$ такой, что $P(x_i)=y_i$ для всех $i$.

Явная формула: $P(x)=\sum_{i=1}^n y_i\prod_{j\ne i}\frac{x-x_j}{x_i-x_j}$.

\textbf{32. Свойства комплексного сопряжения (6 штук):}
\begin{itemize}
\item $\overline{\bar{z}}=z$ (двойное сопряжение);
\item $\bar{a}=a$ для $a\in\R$ (сопряжение вещественного);
\item $\overline{z+w}=\bar{z}+\bar{w}$ (сопряжение суммы);
\item $\overline{z\cdot w}=\bar{z}\cdot\bar{w}$ (сопряжение произведения);
\item $|z|^2=z\cdot\bar{z}$ (связь с модулем);
\item $\overline{z^{-1}}=(\bar{z})^{-1}$ (сопряжённое к обратному).
\end{itemize}

\textbf{33. Формула для деления комплексных чисел:}
\[\frac{z}{w}=\frac{z\cdot\bar{w}}{|w|^2}=\frac{z\cdot\bar{w}}{w\cdot\bar{w}}.\]

\textbf{34. Теорема о произведении комплексных чисел в тригонометрической форме:}
\[z_1\cdot z_2=r_1r_2(\cos(\varphi_1+\varphi_2)+i\sin(\varphi_1+\varphi_2)).\]

\textit{Следствие о делении:}
\[\frac{z_1}{z_2}=\frac{r_1}{r_2}(\cos(\varphi_1-\varphi_2)+i\sin(\varphi_1-\varphi_2)).\]

\textbf{35. Формула Муавра:} $z^n=r^n(\cos(n\varphi)+i\sin(n\varphi))$.

\textbf{36. Формула для комплексного корня:} См. определение 44.

\textbf{37. Корень из произведения:} Множество всех значений $\sqrt[n]{z\cdot w}$ совпадает с множеством всех произведений значений $\sqrt[n]{z}\cdot\sqrt[n]{w}$.

\textbf{38. Теорема Безу:} Многочлен $P(x)$ делится на $(x-\alpha)$ без остатка тогда и только тогда, когда $P(\alpha)=0$.

\textbf{39. Основная теорема алгебры:} Любой многочлен с комплексными коэффициентами степени $\ge1$ имеет хотя бы один комплексный корень.

\textbf{40. Теорема о разложении многочлена на линейные множители:} Любой многочлен $P(x)$ степени $n$ над $\C$ представляется в виде:
\[P(x)=c(x-\alpha_1)(x-\alpha_2)\cdots(x-\alpha_n),\]
где $c$ — старший коэффициент, $\alpha_1,\ldots,\alpha_n$ — корни (с учётом кратности).

\textbf{41. Утверждение о комплексных корнях многочлена с вещественными коэффициентами:} Если многочлен имеет вещественные коэффициенты и $\alpha$ — его корень, то $\bar{\alpha}$ также является корнем той же кратности.

\textbf{42. Утверждение о разложении вещественного многочлена на скобки:} Любой многочлен с вещественными коэффициентами раскладывается в произведение линейных множителей $(x-\alpha)$, где $\alpha\in\R$, и квадратичных множителей $(x^2+px+q)$ с отрицательным дискриминантом $p^2-4q<0$.

\subsection*{Векторные пространства}

\textbf{43. Простейшие свойства векторных пространств (7 штук):}
\begin{itemize}
\item Свойство нулевого вектора: $0+v=v$ (единственность);
\item Свойство противоположного: $v+(-v)=0$ (единственность);
\item Умножение на ноль: $0\cdot v=0$ (нулевой вектор);
\item Умножение на $-1$: $(-1)\cdot v=-v$;
\item Умножение нуля: $\alpha\cdot0=0$;
\item Противоположный к сумме: $-(v+w)=-v-w$;
\item Дважды противоположный: $-(-v)=v$.
\end{itemize}

\textbf{44. Эквивалентное определение подпространства:} $U$ — подпространство $V$ $\Leftrightarrow$ $U\ne\varnothing$ и для любых $u,v\in U$ и любых $\alpha,\beta\in\mathbb{F}$ выполнено $\alpha u+\beta v\in U$ (замкнутость относительно линейных комбинаций).

\textbf{45. Три свойства линейной зависимости:}
\begin{enumerate}
\item Если в системе есть нулевой вектор, то система линейно зависима;
\item Если подсистема линейно зависима, то и вся система линейно зависима;
\item Если система линейно независима, то любая её подсистема линейно независима.
\end{enumerate}

\textbf{46. Основная лемма о линейной зависимости:} Пусть система $\{v_1,\ldots,v_k\}$ линейно независима, а система $\{v_1,\ldots,v_k,w\}$ линейно зависима. Тогда $w\in\langle v_1,\ldots,v_k\rangle$.

\textbf{47. Свойство линейной оболочки:} $\langle v_1,\ldots,v_k\rangle$ — наименьшее подпространство, содержащее векторы $v_1,\ldots,v_k$.

\textbf{48. Эквивалентные определения базиса (4 штуки):} Следующие условия эквивалентны:
\begin{enumerate}
\item $B$ — линейно независимая и полная система;
\item $B$ — максимальная линейно независимая система;
\item $B$ — минимальная полная система;
\item Любой вектор единственным образом представляется в виде линейной комбинации векторов из $B$.
\end{enumerate}

\textbf{49. Лемма о дополнении до базиса:} Любую линейно независимую систему векторов можно дополнить до базиса векторного пространства.

\textbf{50. Лемма о выборе базиса:} Из любой полной системы векторов можно выбрать базис.

\textbf{51. Теорема о корректности ранга:} Все базисы данной системы векторов имеют одинаковое число элементов.

\textbf{52. Теорема о свойствах линейной зависимости набора столбцов при совершении элементарных операций:} Линейная зависимость (независимость) системы столбцов матрицы не меняется при элементарных преобразованиях строк.

\end{multicols}

\newpage

\begin{multicols}{3}

\section*{АЛГОРИТМЫ}

\subsection*{1. Прямой ход метода Гаусса (Гаусса–Жордана)}

\textbf{Постановка задачи:} Дана СЛАУ (или матрица). Требуется привести расширенную матрицу к ступенчатому виду.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Рассмотреть первый столбец. Если он ненулевой, выбрать любой ненулевой элемент как лидер (обычно первый ненулевой).
\item Если лидер не в первой строке, поменять строки местами (ЭП II).
\item С помощью ЭП I типа обнулить все элементы под лидером.
\item Перейти к подматрице, полученной вычёркиванием первой строки и рассмотренных столбцов.
\item Повторить процесс для подматрицы.
\item Продолжать до тех пор, пока не получится ступенчатый вид.
\end{enumerate}

\textbf{Количество шагов:} $O(n^3)$ арифметических операций для матрицы $n\times n$.

\subsection*{2. Обратный ход метода Гаусса}

\textbf{Постановка задачи:} Дана матрица в улучшенном ступенчатом виде. Требуется выписать все решения СЛАУ.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Проверить совместность: если есть строка вида $(0\,0\,\ldots\,0\,|\,b)$, где $b\ne0$, система несовместна.
\item Определить свободные переменные (столбцы без лидеров).
\item Свободным переменным присвоить произвольные значения (параметры $t_1,t_2,\ldots$).
\item Выразить главные переменные через свободные, двигаясь снизу вверх по строкам (каждая строка даёт выражение для одной главной переменной).
\item Записать общее решение.
\end{enumerate}

\textbf{Количество шагов:} $O(n^2)$ операций.

\subsection*{3. Нахождение порядка подстановки}

\textbf{Постановка задачи:} Дана подстановка $\sigma$. Требуется найти её порядок.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Разложить подстановку в произведение независимых циклов.
\item Для этого:
   \begin{itemize}
   \item Взять любой элемент $a_1$;
   \item Построить его орбиту: $a_1\to\sigma(a_1)\to\sigma^2(a_1)\to\cdots$ до возврата в $a_1$;
   \item Получили цикл $(a_1\,\sigma(a_1)\,\sigma^2(a_1)\,\ldots)$;
   \item Взять следующий не рассмотренный элемент, построить его орбиту;
   \item Продолжать до тех пор, пока все элементы не будут рассмотрены.
   \end{itemize}
\item Найти длины всех полученных циклов: $k_1,k_2,\ldots,k_m$.
\item Порядок подстановки: $\mathrm{ord}(\sigma)=\mathrm{НОК}(k_1,k_2,\ldots,k_m)$.
\end{enumerate}

\subsection*{4. Вычисление определителя методом Гаусса}

\textbf{Постановка задачи:} Дана квадратная матрица $A$ размера $n\times n$. Требуется вычислить $\det A$.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Применить прямой ход метода Гаусса, приводя матрицу к треугольному виду.
\item При этом запоминать:
   \begin{itemize}
   \item Количество перестановок строк (ЭП II типа) — пусть это $p$;
   \item Все коэффициенты $\alpha$, на которые умножались строки (ЭП III типа) — пусть их произведение $c$.
   \end{itemize}
\item После приведения к треугольному виду:
   \[\det A=(-1)^p\cdot c\cdot a'_{11}\cdot a'_{22}\cdots a'_{nn},\]
   где $a'_{ii}$ — диагональные элементы полученной треугольной матрицы.
\end{enumerate}

\textbf{Количество шагов:} $O(n^3)$ операций.

\subsection*{5. Деление комплексных чисел в алгебраической форме}

\textbf{Постановка задачи:} Даны комплексные числа $z_1=a+bi$ и $z_2=c+di$ ($z_2\ne0$). Требуется найти $\frac{z_1}{z_2}$ в алгебраической форме.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Умножить числитель и знаменатель на комплексно сопряжённое к знаменателю:
   \[\frac{a+bi}{c+di}=\frac{(a+bi)(c-di)}{(c+di)(c-di)}.\]
\item Раскрыть скобки в числителе:
   \[(a+bi)(c-di)=ac-adi+bci-bdi^2=ac+bd+(bc-ad)i.\]
\item Вычислить знаменатель:
   \[(c+di)(c-di)=c^2+d^2.\]
\item Разделить:
   \[\frac{z_1}{z_2}=\frac{ac+bd}{c^2+d^2}+\frac{bc-ad}{c^2+d^2}i.\]
\end{enumerate}

\subsection*{6. Перевод из алгебраической в тригонометрическую форму}

\textbf{Постановка задачи:} Дано комплексное число $z=a+bi$ в алгебраической форме. Требуется записать его в тригонометрической форме $z=r(\cos\varphi+i\sin\varphi)$.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Вычислить модуль: $r=|z|=\sqrt{a^2+b^2}$.
\item Если $r=0$, то $z=0$ (аргумент не определён). Конец.
\item Вычислить $\cos\varphi=\frac{a}{r}$ и $\sin\varphi=\frac{b}{r}$.
\item Определить аргумент $\varphi$ по знакам $a$ и $b$ (четверти):
   \begin{itemize}
   \item I четверть ($a>0$, $b>0$): $\varphi=\arctan\frac{b}{a}$;
   \item II четверть ($a<0$, $b>0$): $\varphi=\pi-\arctan\frac{|b|}{|a|}$ или $\varphi=\arctan\frac{b}{a}+\pi$;
   \item III четверть ($a<0$, $b<0$): $\varphi=-\pi+\arctan\frac{|b|}{|a|}$ или $\varphi=\arctan\frac{b}{a}-\pi$;
   \item IV четверть ($a>0$, $b<0$): $\varphi=-\arctan\frac{|b|}{a}$ или $\varphi=\arctan\frac{b}{a}$.
   \end{itemize}
   (Или использовать функцию $\mathrm{atan2}(b,a)$.)
\item Записать ответ: $z=r(\cos\varphi+i\sin\varphi)$.
\end{enumerate}

\subsection*{7. Проверка набора столбцов на линейную зависимость}

\textbf{Постановка задачи:} Даны векторы-столбцы $v_1,v_2,\ldots,v_k$ размера $n$. Требуется определить, линейно зависимы они или независимы.

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Составить матрицу $A$ размера $n\times k$, столбцами которой являются данные векторы: $A=(v_1\,v_2\,\ldots\,v_k)$.
\item Привести матрицу $A$ к ступенчатому виду с помощью элементарных преобразований строк.
\item Подсчитать число ненулевых строк в ступенчатом виде (это ранг матрицы $\rk A$).
\item \textbf{Вывод:}
   \begin{itemize}
   \item Если $\rk A=k$ (число ненулевых строк равно числу столбцов), то векторы линейно независимы.
   \item Если $\rk A<k$ (есть нулевые строки), то векторы линейно зависимы.
   \end{itemize}
\end{enumerate}

\subsection*{8. Алгоритм выбора базиса из набора векторов}

\textbf{Постановка задачи:} Дана система векторов $v_1,v_2,\ldots,v_k$. Требуется выбрать из неё базис (максимальную линейно независимую подсистему).

\textbf{Ход алгоритма:}
\begin{enumerate}
\item Составить матрицу $A$, столбцами которой являются данные векторы: $A=(v_1\,v_2\,\ldots\,v_k)$.
\item Привести матрицу к ступенчатому (или улучшенному ступенчатому) виду с помощью элементарных преобразований строк. Запомнить, какие столбцы соответствуют лидерам строк.
\item \textbf{Выбрать в исходной матрице $A$ столбцы, соответствующие позициям лидеров.} Эти векторы образуют базис системы.
\item (Альтернативный подход: последовательно проверять векторы на линейную независимость с уже выбранными, добавляя вектор в базис, если он не выражается через предыдущие.)
\end{enumerate}

\textbf{Замечание:} важно выбирать столбцы из \textit{исходной} матрицы, а не из преобразованной!

\end{multicols}

\newpage

\begin{multicols}{3}

\section*{ЛЁГКИЕ ДОКАЗАТЕЛЬСТВА (2 балла)}

\subsection*{1. Ассоциативность произведения матриц}

Нужно показать: $(AB)C=A(BC)$.

\textbf{Доказательство:} Вычислим элемент с индексом $(i,j)$:
\begin{align*}
((AB)C)_{ij}&=\sum_k(AB)_{ik}\cdot c_{kj}=\sum_k\left(\sum_l a_{il}b_{lk}\right)c_{kj}\\
&=\sum_{l,k}a_{il}b_{lk}c_{kj}=\sum_l a_{il}\left(\sum_k b_{lk}c_{kj}\right)\\
&=\sum_l a_{il}(BC)_{lj}=(A(BC))_{ij}.
\end{align*}
Равенство элементов $\Rightarrow$ равенство матриц. $\square$

\subsection*{2. Дистрибутивность произведения}

\textbf{Утверждение:} $(A+B)C=AC+BC$ и $A(B+C)=AB+AC$.

\textbf{Доказательство:} Вычислим элементы:
\begin{align*}
((A+B)C)_{ij}&=\sum_k(A+B)_{ik}c_{kj}=\sum_k(a_{ik}+b_{ik})c_{kj}\\
&=\sum_k a_{ik}c_{kj}+\sum_k b_{ik}c_{kj}=(AC)_{ij}+(BC)_{ij}.
\end{align*}
Второе свойство доказывается аналогично. $\square$

\subsection*{3. Свойства обратных матриц}

\textbf{Утверждение 1:} $(AB)^{-1}=B^{-1}A^{-1}$.

\textbf{Доказательство:} Проверим:
\[(AB)(B^{-1}A^{-1})=A(BB^{-1})A^{-1}=AEA^{-1}=AA^{-1}=E.\]
Аналогично $(B^{-1}A^{-1})(AB)=E$. По единственности обратной $(AB)^{-1}=B^{-1}A^{-1}$. $\square$

\textbf{Утверждение 2:} $(A^T)^{-1}=(A^{-1})^T$.

\textbf{Доказательство:}
\[(A^{-1})^T\cdot A^T=(AA^{-1})^T=E^T=E.\]
Аналогично $A^T\cdot(A^{-1})^T=E$. Значит, $(A^T)^{-1}=(A^{-1})^T$. $\square$

\subsection*{4. След произведения матриц}

\textbf{Утверждение:} $\Tr(AB)=\Tr(BA)$.

\textbf{Доказательство:}
\begin{align*}
\Tr(AB)&=\sum_i(AB)_{ii}=\sum_i\sum_j a_{ij}b_{ji}\\
&=\sum_j\sum_i b_{ji}a_{ij}=\sum_j(BA)_{jj}=\Tr(BA).
\end{align*}
$\square$

\subsection*{5. Единственность обратной матрицы}

\textbf{Утверждение:} Если $AB=BA=E$ и $AC=CA=E$, то $B=C$.

\textbf{Доказательство:}
\[B=EB=(CA)B=C(AB)=CE=C.\]
$\square$

\subsection*{6. Эквивалентность систем при ЭП I типа}

\textbf{Утверждение:} Если к одной строке системы прибавить другую, умноженную на число, то новая система эквивалентна исходной.

\textbf{Доказательство:} Пусть $(x_1,\ldots,x_n)$ — решение исходной системы. Рассмотрим новое $i$-е уравнение (после $s_i\to s_i+\alpha s_j$). Левая часть:
\[\sum_k a_{ik}x_k+\alpha\sum_k a_{jk}x_k=b_i+\alpha b_j=\text{правая часть нового ур-я}.\]
Значит, решение исходной системы является решением новой.

Обратно: операция $s_i\to s_i+\alpha s_j$ обратима ($s_i\to s_i-\alpha s_j$), поэтому решение новой системы является решением исходной. $\square$

\subsection*{7. Решения при фиксированных свободных переменных}

\textbf{Утверждение:} Если придать фиксированные значения свободным переменным, то главные переменные определяются однозначно (если система совместна).

\textbf{Доказательство:} В ступенчатом виде каждая ненулевая строка содержит ровно одну главную переменную (лидер). При фиксированных свободных переменных каждое уравнение превращается в линейное относительно одной главной переменной $\Rightarrow$ главная переменная определяется однозначно.

Если встретилось экзотическое уравнение $0=b\ne0$, система несовместна. $\square$

\subsection*{8. Возможное количество решений СЛАУ}

\textbf{Утверждение:} СЛАУ имеет либо 0, либо 1, либо $\infty$ решений.

\textbf{Доказательство:}
\begin{itemize}
\item Если есть экзотическое уравнение — 0 решений (несовместна).
\item Если система совместна и свободных переменных нет — 1 решение (все переменные главные, определяются однозначно).
\item Если система совместна и есть хотя бы одна свободная переменная — $\infty$ решений (свободным переменным можно придавать любые значения). $\square$
\end{itemize}

\subsection*{9. Ассоциативность композиции подстановок}

\textbf{Утверждение:} $(\sigma\tau)\rho=\sigma(\tau\rho)$.

\textbf{Доказательство:} Проверим действие на произвольный элемент $i$:
\[((\sigma\tau)\rho)(i)=(\sigma\tau)(\rho(i))=\sigma(\tau(\rho(i))).\]
\[(\sigma(\tau\rho))(i)=\sigma((\tau\rho)(i))=\sigma(\tau(\rho(i))).\]
Действия совпадают $\Rightarrow$ подстановки равны. $\square$

\subsection*{10. Теорема о разложении в независимые циклы}

\textbf{Утверждение:} Любая подстановка единственным образом (с точностью до порядка) представляется произведением независимых циклов.

\textbf{Доказательство (схема):} Для каждого элемента $a$ строим его орбиту: $a\to\sigma(a)\to\sigma^2(a)\to\cdots$ до возврата в $a$. Орбита образует цикл. Разные орбиты не пересекаются (каждый элемент попадает ровно в одну орбиту). Подстановка есть произведение всех полученных циклов. Единственность следует из единственности разбиения на орбиты. $\square$

\subsection*{11. Произведение подстановки на транспозицию}

\textbf{Утверждение:} $\sigma(i\,j)$ меняет местами значения $\sigma(i)$ и $\sigma(j)$, остальные не меняет.

\textbf{Доказательство:} Вычислим:
\[(\sigma(i\,j))(k)=\begin{cases}
\sigma(j), & k=i,\\
\sigma(i), & k=j,\\
\sigma(k), & k\ne i,j.
\end{cases}\]
Действительно, $(i\,j)(k)=j$ при $k=i$, $(i\,j)(k)=i$ при $k=j$, $(i\,j)(k)=k$ иначе. Подставляя в $\sigma$, получаем утверждение. $\square$

\subsection*{12. Знак композиции подстановок}

\textbf{Утверждение:} $\sgn(\sigma\tau)=\sgn(\sigma)\cdot\sgn(\tau)$.

\textbf{Доказательство (через транспозиции):} Представим $\sigma=t_1\cdots t_k$ и $\tau=s_1\cdots s_m$, где $t_i$, $s_j$ — транспозиции. Тогда $\sigma\tau=t_1\cdots t_ks_1\cdots s_m$. Чётность $\sigma\tau$ определяется чётностью $k+m$, а $\sgn(\sigma\tau)=(-1)^{k+m}=(-1)^k\cdot(-1)^m=\sgn(\sigma)\cdot\sgn(\tau)$. $\square$

\textit{Следствие:} $1=\sgn(e)=\sgn(\sigma\sigma^{-1})=\sgn(\sigma)\sgn(\sigma^{-1})\Rightarrow\sgn(\sigma^{-1})=\sgn(\sigma)$. $\square$

\subsection*{13. Определитель транспонированной матрицы}

\textbf{Утверждение:} $\det(A^T)=\det A$.

\textbf{Доказательство:}
\begin{align*}
\det(A^T)&=\sum_{\sigma}\sgn(\sigma)\prod_i a^T_{i,\sigma(i)}=\sum_{\sigma}\sgn(\sigma)\prod_i a_{\sigma(i),i}\\
&=\sum_{\sigma}\sgn(\sigma)a_{\sigma(1),1}\cdots a_{\sigma(n),n}.
\end{align*}
При замене индекса $\sigma\to\tau=\sigma^{-1}$ получаем:
\[\det(A^T)=\sum_{\tau}\sgn(\tau^{-1})a_{1,\tau(1)}\cdots a_{n,\tau(n)}=\sum_{\tau}\sgn(\tau)a_{1,\tau(1)}\cdots a_{n,\tau(n)}=\det A.\]
$\square$

\subsection*{14. Определитель треугольной матрицы}

\textbf{Утверждение:} Определитель верхне- (или нижне-) треугольной матрицы равен произведению диагональных элементов.

\textbf{Доказательство:} Пусть $A$ верхнетреугольная: $a_{ij}=0$ при $i>j$. В формуле для определителя слагаемое, соответствующее подстановке $\sigma$, содержит множители $a_{1,\sigma(1)}, a_{2,\sigma(2)},\ldots$ Если $\sigma(i)<i$ для некоторого $i$, то $a_{i,\sigma(i)}=0$ (элемент ниже диагонали). Ненулевое слагаемое только когда $\sigma(i)\ge i$ для всех $i$. Но поскольку $\sigma$ — биекция, из $\sigma(i)\ge i$ для всех $i$ следует $\sigma(i)=i$ для всех $i$, т.е. $\sigma=e$. Поэтому:
\[\det A=\sgn(e)\cdot a_{11}a_{22}\cdots a_{nn}=a_{11}a_{22}\cdots a_{nn}.\]
$\square$

\subsection*{15. Интерполяционный многочлен Лагранжа}

\textbf{Утверждение:} Для попарно различных $x_1,\ldots,x_n$ и любых $y_1,\ldots,y_n$ существует единственный многочлен степени $\le n-1$ такой, что $P(x_i)=y_i$.

\textbf{Доказательство:}

\textit{Единственность:} Пусть $P$ и $Q$ — два таких многочлена. Тогда $R(x)=P(x)-Q(x)$ имеет степень $\le n-1$ и обращается в нуль в точках $x_1,\ldots,x_n$ (всего $n$ корней). Многочлен степени $\le n-1$ с $n$ корнями $\Rightarrow$ $R\equiv0$ $\Rightarrow$ $P=Q$.

\textit{Существование:} Явная формула:
\[P(x)=\sum_{i=1}^n y_i\prod_{j\ne i}\frac{x-x_j}{x_i-x_j}.\]
Проверка: $P(x_k)=y_k\cdot1+\sum_{i\ne k}y_i\cdot0=y_k$. $\square$

\subsection*{16. Произведение в тригонометрической форме. Формула Муавра}

\textbf{Утверждение:} $z_1z_2=r_1r_2(\cos(\varphi_1+\varphi_2)+i\sin(\varphi_1+\varphi_2))$.

\textbf{Доказательство:}
\begin{align*}
z_1z_2&=r_1(\cos\varphi_1+i\sin\varphi_1)\cdot r_2(\cos\varphi_2+i\sin\varphi_2)\\
&=r_1r_2(\cos\varphi_1\cos\varphi_2-\sin\varphi_1\sin\varphi_2+i(\sin\varphi_1\cos\varphi_2+\cos\varphi_1\sin\varphi_2))\\
&=r_1r_2(\cos(\varphi_1+\varphi_2)+i\sin(\varphi_1+\varphi_2)).
\end{align*}
$\square$

\textbf{Следствие (деление):} Аналогично выводится формула для деления с разностью углов.

\textbf{Формула Муавра:} $z^n=r^n(\cos(n\varphi)+i\sin(n\varphi))$.

\textbf{Доказательство:} Индукция по $n$, используя формулу для произведения. $\square$

\subsection*{17. Комплексные корни вещественного многочлена}

\textbf{Утверждение:} Если $P(x)$ имеет вещественные коэффициенты и $\alpha$ — корень, то $\bar{\alpha}$ тоже корень.

\textbf{Доказательство:} $P(x)=\sum c_kx^k$, где $c_k\in\R$. Тогда:
\[P(\bar{\alpha})=\sum c_k\bar{\alpha}^k=\sum c_k\overline{\alpha^k}=\sum\overline{c_k\alpha^k}=\overline{\sum c_k\alpha^k}=\overline{P(\alpha)}=\bar{0}=0.\]
$\square$

\subsection*{18. Разложение вещественного многочлена}

\textbf{Утверждение:} Любой многочлен с вещественными коэффициентами раскладывается в произведение линейных и квадратичных множителей с отрицательным дискриминантом.

\textbf{Доказательство:} По ОТА многочлен раскладывается на линейные множители над $\C$. Вещественные корни дают линейные множители. Комплексные корни идут сопряжёнными парами. Каждая пара $\alpha,\bar{\alpha}$ даёт:
\[(x-\alpha)(x-\bar{\alpha})=x^2-(\alpha+\bar{\alpha})x+\alpha\bar{\alpha}=x^2-2\mathrm{Re}(\alpha)x+|\alpha|^2.\]
Дискриминант: $4\mathrm{Re}^2(\alpha)-4|\alpha|^2=-4\mathrm{Im}^2(\alpha)<0$ (если $\alpha\notin\R$). $\square$

\subsection*{19. Простейшие свойства векторных пространств}

Доказываются из 8 аксиом.

\textbf{Пример 1:} $0\cdot v=0$.

\textbf{Доказательство:} $0\cdot v=(0+0)\cdot v=0\cdot v+0\cdot v$. Прибавим $-(0\cdot v)$ к обеим частям: $0=0\cdot v$. $\square$

\textbf{Пример 2:} $(-1)\cdot v=-v$.

\textbf{Доказательство:} $v+(-1)\cdot v=1\cdot v+(-1)\cdot v=(1+(-1))\cdot v=0\cdot v=0$. Значит, $(-1)\cdot v$ — противоположный к $v$. $\square$

Остальные свойства доказываются аналогично. $\square$

\end{multicols}

\newpage

\begin{multicols}{3}

\section*{СЛОЖНЫЕ ДОКАЗАТЕЛЬСТВА (3 балла)}

\subsection*{1. Возведение цикла в степень. Порядок подстановки через циклы}

\textbf{Утверждение 1:} $(a_1\,a_2\,\ldots\,a_k)^m$ распадается на $\gcd(k,m)$ независимых циклов длины $k/\gcd(k,m)$.

\textbf{Доказательство:} При возведении цикла в степень $m$ каждый элемент сдвигается на $m$ позиций. $a_i$ переходит в $a_{i+m\bmod k}$. Орбита элемента $a_i$ имеет длину, равную наименьшему $t$ такому, что $i+tm\equiv i\pmod{k}$, т.е. $k|tm$. Наименьшее такое $t=k/\gcd(k,m)$. Элементы разбиваются на орбиты (циклы) длины $k/\gcd(k,m)$, всего орбит $\gcd(k,m)$. $\square$

\textbf{Утверждение 2:} Порядок подстановки $=\mathrm{НОК}$ длин циклов в разложении.

\textbf{Доказательство:} Пусть $\sigma=\sigma_1\sigma_2\cdots\sigma_m$ — разложение на независимые циклы длин $k_1,\ldots,k_m$. Независимые циклы коммутируют, поэтому $\sigma^n=\sigma_1^n\cdots\sigma_m^n$. Цикл длины $k_i$ имеет порядок $k_i$ (возвращается в исходное состояние через $k_i$ шагов). $\sigma^n=e\Leftrightarrow\sigma_i^n=e$ для всех $i\Leftrightarrow k_i|n$ для всех $i\Leftrightarrow\mathrm{НОК}(k_1,\ldots,k_m)|n$. Наименьшее такое $n=\mathrm{НОК}(k_1,\ldots,k_m)$. $\square$

\subsection*{2. Чётность произведения подстановки на транспозицию}

\textbf{Утверждение:} $\sgn(\sigma(i\,j))=-\sgn(\sigma)$.

\textbf{Доказательство:} Рассмотрим инверсии. Пусть $\sigma(i)=a$, $\sigma(j)=b$. Транспозиция $(i\,j)$ меняет местами $i$ и $j$. Инверсии в $\sigma(i\,j)$ отличаются от инверсий в $\sigma$ только для пар, содержащих $i$ или $j$.

Пара $(i,j)$: в $\sigma$ инверсия $\Leftrightarrow$ $a>b$. В $\sigma(i\,j)$ инверсия $\Leftrightarrow$ $b>a$. Чётность меняется.

Для $k\ne i,j$: пара $(i,k)$ в $\sigma$ инверсия $\Leftrightarrow$ $a>\sigma(k)$ или $\sigma(k)>a$ (в зависимости от $k<i$ или $k>i$). После умножения на $(i\,j)$ элемент $i$ переходит в $j$, поэтому проверяем пару $(j,k)$. Аналогично для пары $(k,j)$.

Детальный подсчёт показывает, что общее изменение чётности — это изменение чётности на 1 (переворот одной пары $(i,j)$) плюс чётное число изменений от пар $(i,k)$ и $(j,k)$. Итого: чётность меняется. $\square$

\textit{(Более строгое доказательство требует аккуратного подсчёта всех инверсий.)}

\subsection*{3. Разложение подстановки на транспозиции. Чётность}

\textbf{Утверждение 1:} Любая подстановка представима произведением транспозиций.

\textbf{Доказательство:} Достаточно показать для цикла (по теореме о разложении на циклы). Цикл длины $k$:
\[(a_1\,a_2\,\ldots\,a_k)=(a_1\,a_k)(a_1\,a_{k-1})\cdots(a_1\,a_2).\]
Проверка: правая часть последовательно переставляет $a_1\to a_2\to\cdots\to a_k\to a_1$. $\square$

\textbf{Утверждение 2:} Чётность подстановки не зависит от разложения на транспозиции.

\textbf{Доказательство:} По лемме о произведении на транспозицию, каждая транспозиция меняет знак. Если $\sigma=t_1\cdots t_k$, то $\sgn(\sigma)=(-1)^k$. Если есть другое разложение $\sigma=s_1\cdots s_m$, то $\sgn(\sigma)=(-1)^m$. Значит, $(-1)^k=(-1)^m$, т.е. $k$ и $m$ имеют одинаковую чётность. $\square$

\subsection*{4. Кососимметричность определителя}

\textbf{Утверждение:} При перестановке двух строк определитель меняет знак.

\textbf{Доказательство:} Пусть $A'$ получена из $A$ перестановкой строк $i$ и $j$ (т.е. $i$-я строка $A'$ равна $j$-й строке $A$, и наоборот). Обозначим строки $A$ как $r_1,\ldots,r_n$. Тогда:
\begin{align*}
\det A'&=\sum_{\sigma}\sgn(\sigma)a'_{1,\sigma(1)}\cdots a'_{n,\sigma(n)}.
\end{align*}
Заметим, что $a'_{k,l}=a_{k,l}$ при $k\ne i,j$ и $a'_{i,l}=a_{j,l}$, $a'_{j,l}=a_{i,l}$. Перепишем:
\[\det A'=\sum_{\sigma}\sgn(\sigma)a_{1,\sigma(1)}\cdots a_{j,\sigma(i)}\cdots a_{i,\sigma(j)}\cdots a_{n,\sigma(n)}.\]
Заменим индекс: $\tau=\sigma(i\,j)$ (композиция $\sigma$ и транспозиции). Тогда $\sigma=\tau(i\,j)$, $\sgn(\sigma)=-\sgn(\tau)$, $\sigma(i)=\tau(j)$, $\sigma(j)=\tau(i)$. Получаем:
\[\det A'=\sum_{\tau}\sgn(\tau(i\,j))a_{1,\tau(1)}\cdots a_{i,\tau(i)}\cdots a_{j,\tau(j)}\cdots=-\sum_{\tau}\sgn(\tau)a_{1,\tau(1)}\cdots=-\det A.\]
$\square$

\textit{Следствие:} Если две строки равны, то $\det A=-\det A\Rightarrow\det A=0$. $\square$

\subsection*{5. Изменение определителя при элементарных операциях}

Следует из полилинейности и кососимметричности:

\textbf{ЭП I:} $\det(\ldots,s_i+\alpha s_j,\ldots)=\det(\ldots,s_i,\ldots)+\alpha\det(\ldots,s_j,\ldots)=\det A+0=\det A$ (второе слагаемое $=0$, т.к. две строки равны).

\textbf{ЭП II:} Кососимметричность.

\textbf{ЭП III:} Полилинейность: $\det(\ldots,\alpha s_i,\ldots)=\alpha\det(\ldots,s_i,\ldots)$. $\square$

\subsection*{6. Кососимметричная полилинейная функция: $\Phi(A)=\Phi(E)\det A$}

\textbf{Утверждение:} Пусть $\Phi$ — полилинейная и кососимметричная функция от строк матрицы $n\times n$. Тогда $\Phi(A)=\Phi(E)\det A$.

\textbf{Доказательство:} Разложим каждую строку $s_i$ по базису: $s_i=\sum_j a_{ij}e_j$, где $e_j$ — стандартные базисные векторы. По полилинейности:
\[\Phi(A)=\Phi(s_1,\ldots,s_n)=\sum_{j_1,\ldots,j_n}a_{1j_1}\cdots a_{nj_n}\Phi(e_{j_1},\ldots,e_{j_n}).\]
По кососимметричности $\Phi(e_{j_1},\ldots,e_{j_n})=0$, если есть повторяющиеся индексы. Если все индексы различны, то $(j_1,\ldots,j_n)$ — подстановка $\sigma$: $j_i=\sigma(i)$. При этом:
\[\Phi(e_{\sigma(1)},\ldots,e_{\sigma(n)})=\sgn(\sigma)\Phi(e_1,\ldots,e_n)=\sgn(\sigma)\Phi(E).\]
Подставляя:
\[\Phi(A)=\sum_{\sigma\in S_n}\sgn(\sigma)a_{1,\sigma(1)}\cdots a_{n,\sigma(n)}\Phi(E)=\Phi(E)\det A.\]
$\square$

\subsection*{7. Определитель с углом нулей}

\textbf{Утверждение:} $\det\begin{pmatrix}A&B\\0&C\end{pmatrix}=\det A\cdot\det C$, где $A$ размера $k\times k$, $C$ размера $(n-k)\times(n-k)$.

\textbf{Доказательство:} Рассмотрим $\Phi(C)=\det\begin{pmatrix}A&B\\0&C\end{pmatrix}$ как функцию от строк $C$ (нижняя часть). Это полилинейная и кососимметричная функция от строк $C$. По теореме 6:
\[\Phi(C)=\Phi(E_{n-k})\det C.\]
Вычислим $\Phi(E_{n-k})$: это $\det\begin{pmatrix}A&B\\0&E_{n-k}\end{pmatrix}$. Приведём к треугольному виду элементарными операциями (вычитая из верхних строк нижние, обнуляя $B$):
\[\det\begin{pmatrix}A&B\\0&E\end{pmatrix}=\det\begin{pmatrix}A&0\\0&E\end{pmatrix}=\det A\cdot\det E=\det A.\]
Итого: $\Phi(C)=\det A\cdot\det C$. $\square$

\subsection*{8. Определитель произведения}

\textbf{Утверждение:} $\det(AB)=\det A\cdot\det B$.

\textbf{Доказательство:} Рассмотрим $\Phi(C)=\det(AC)$ как функцию от строк матрицы $C$. Если $c_1,\ldots,c_n$ — строки $C$, то строки $AC$ есть $c_1A,\ldots,c_nA$. Проверим полилинейность и кососимметричность $\Phi$:

\textit{Полилинейность:} $\Phi(\ldots,\alpha c_i+\beta c'_i,\ldots)=\det(\ldots,(\alpha c_i+\beta c'_i)A,\ldots)=\det(\ldots,\alpha c_iA+\beta c'_iA,\ldots)=\alpha\det(\ldots,c_iA,\ldots)+\beta\det(\ldots,c'_iA,\ldots)=\alpha\Phi(\ldots,c_i,\ldots)+\beta\Phi(\ldots,c'_i,\ldots)$.

\textit{Кососимметричность:} аналогично.

По теореме 6: $\Phi(C)=\Phi(E)\det C$. Вычислим $\Phi(E)=\det(AE)=\det A$. Итого: $\det(AC)=\det A\cdot\det C$. Подставляя $C=B$: $\det(AB)=\det A\cdot\det B$. $\square$

\subsection*{9. Разложение определителя по строке}

\textbf{Утверждение:} $\det A=\sum_{j=1}^n a_{ij}A_{ij}$.

\textbf{Доказательство:} Разложим $i$-ю строку: $s_i=\sum_j a_{ij}e_j$. По полилинейности:
\[\det A=\sum_j a_{ij}\det(\ldots,e_j,\ldots),\]
где $e_j$ стоит на $i$-м месте. Вычислим $\det(\ldots,e_j,\ldots)$: переставим строку $e_j$ на $j$-ю позицию (это $|i-j|$ перестановок), получим знак $(-1)^{|i-j|}$. Нет, это неправильно.

\textit{Правильный подход:} Рассмотрим матрицу, где $i$-я строка — $e_j$. Разложим по формуле определителя через подстановки. Ненулевое слагаемое только когда $\sigma(i)=j$. Зафиксируем $\sigma(i)=j$. Остальные элементы $\sigma$ действуют на $\{1,\ldots,n\}\setminus\{i\}\to\{1,\ldots,n\}\setminus\{j\}$. Это даёт подстановку размера $n-1$, определитель которой — минор $M_{ij}$. Знак зависит от позиции: $(-1)^{i+j}$. Итого: $\det(\ldots,e_j,\ldots)=(-1)^{i+j}M_{ij}=A_{ij}$. Подставляя:
\[\det A=\sum_j a_{ij}A_{ij}.\]
$\square$

\subsection*{10. Фальшивое разложение. Присоединённая матрица}

\textbf{Утверждение 1 (фальшивое разложение):} $\sum_j a_{ij}A_{kj}=0$ при $i\ne k$.

\textbf{Доказательство:} Рассмотрим матрицу $A'$, полученную из $A$ заменой $k$-й строки на $i$-ю. Тогда $A'$ имеет две одинаковые строки $\Rightarrow$ $\det A'=0$. С другой стороны, разложим $\det A'$ по $k$-й строке:
\[\det A'=\sum_j a'_{kj}A'_{kj}=\sum_j a_{ij}A_{kj}=0,\]
т.к. минор $A'_{kj}$ (вычёркивая $k$-ю строку) совпадает с минором $A_{kj}$. $\square$

\textbf{Утверждение 2 (присоединённая матрица):} $AA^*=A^*A=(\det A)E$.

\textbf{Доказательство:} Вычислим элемент $(AA^*)_{ik}$:
\[(AA^*)_{ik}=\sum_j a_{ij}(A^*)_{jk}=\sum_j a_{ij}A_{kj}.\]
При $i=k$: это разложение $\det A$ по $i$-й строке $=\det A$. При $i\ne k$: фальшивое разложение $=0$. Итого: $(AA^*)_{ik}=(\det A)\delta_{ik}=(\det A)E$. Аналогично $A^*A=(\det A)E$. $\square$

\textbf{Формула для обратной:} Если $\det A\ne0$, то $A\cdot\frac{1}{\det A}A^*=E$, т.е. $A^{-1}=\frac{1}{\det A}A^*$. $\square$

\subsection*{11. Теорема Крамера}

\textbf{Утверждение:} Если $\det A\ne0$, то система $Ax=b$ имеет единственное решение $x_i=\frac{\det A_i}{\det A}$, где $A_i$ — матрица с $i$-м столбцом, замененным на $b$.

\textbf{Доказательство:} Из $\det A\ne0$ следует существование $A^{-1}=\frac{1}{\det A}A^*$. Решение: $x=A^{-1}b=\frac{1}{\det A}A^*b$. Вычислим $i$-ю компоненту:
\[x_i=(A^*b)_i=\sum_j(A^*)_{ij}b_j=\sum_j A_{ji}b_j.\]
Это разложение определителя матрицы $A_i$ по $i$-му столбцу (столбцу $b$):
\[\det A_i=\sum_j b_jA_{ji}.\]
Итого: $x_i=\frac{\det A_i}{\det A}$. $\square$

\subsection*{12. Формула для комплексного корня}

\textbf{Утверждение:} Корни уравнения $z^n=w$, где $w=\rho(\cos\psi+i\sin\psi)$, имеют вид:
\[z_k=\sqrt[n]{\rho}\left(\cos\frac{\psi+2\pi k}{n}+i\sin\frac{\psi+2\pi k}{n}\right),\quad k=0,1,\ldots,n-1.\]

\textbf{Доказательство:} Пусть $z=r(\cos\varphi+i\sin\varphi)$. Тогда по формуле Муавра:
\[z^n=r^n(\cos(n\varphi)+i\sin(n\varphi)).\]
Для $z^n=w$ должно выполняться:
\[r^n=\rho,\quad\cos(n\varphi)=\cos\psi,\quad\sin(n\varphi)=\sin\psi.\]
Из первого: $r=\sqrt[n]{\rho}$ (арифметический корень). Из второго и третьего: $n\varphi=\psi+2\pi k$, где $k\in\mathbb{Z}$. Отсюда $\varphi=\frac{\psi+2\pi k}{n}$. Различные значения $z$ получаются при $k=0,1,\ldots,n-1$ (дальше значения повторяются с периодом $n$). $\square$

\subsection*{13. Основная лемма о линейной зависимости}

\textbf{Утверждение:} Пусть $\{v_1,\ldots,v_k\}$ линейно независимы, а $\{v_1,\ldots,v_k,w\}$ линейно зависимы. Тогда $w\in\langle v_1,\ldots,v_k\rangle$.

\textbf{Доказательство:} По условию существует нетривиальная линейная комбинация:
\[\alpha_1v_1+\alpha_2v_2+\cdots+\alpha_kv_k+\beta w=0,\]
где не все коэффициенты нулевые. Покажем, что $\beta\ne0$. Предположим противное: $\beta=0$. Тогда $\alpha_1v_1+\cdots+\alpha_kv_k=0$, и не все $\alpha_i=0$ (иначе комбинация тривиальная). Но это противоречит линейной независимости $\{v_1,\ldots,v_k\}$. Значит, $\beta\ne0$. Тогда:
\[w=-\frac{\alpha_1}{\beta}v_1-\frac{\alpha_2}{\beta}v_2-\cdots-\frac{\alpha_k}{\beta}v_k\in\langle v_1,\ldots,v_k\rangle.\]
$\square$

\end{multicols}

\end{document}